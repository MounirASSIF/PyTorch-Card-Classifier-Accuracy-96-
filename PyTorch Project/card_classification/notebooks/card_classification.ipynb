{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4532039,"sourceType":"datasetVersion","datasetId":2579480}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Card Classification in PyTorch\n\nIn this notebook, we will create an image classifier to detect playing cards.\n\nWe will tackle this problem in 3 parts:\n1. Pytorch Dataset\n2. Pytorch Model\n3. Pytorch Training Loop\n\nAlmost every pytorch model training pipeline meets this paradigm.","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Import Necessary libraries","metadata":{"editable":false}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nimport timm\n\nimport matplotlib.pyplot as plt # For data viz\nimport pandas as pd\nimport numpy as np\nimport sys\nfrom tqdm import tqdm\n\n\nprint('System Version:', sys.version)\nprint('PyTorch version', torch.__version__)\nprint('Torchvision version', torchvision.__version__)\nprint('Numpy version', np.__version__)\nprint('Pandas version', pd.__version__)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:22.407201Z","iopub.execute_input":"2025-06-28T14:49:22.407897Z","iopub.status.idle":"2025-06-28T14:49:27.153523Z","shell.execute_reply.started":"2025-06-28T14:49:22.407864Z","shell.execute_reply":"2025-06-28T14:49:27.152720Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 1. Pytorch Dataset (and Dataloader)\n\nWould you bake a cake without first having the ingredients? No.\n\nThe same thing can be said for training a pytorch model without first having the dataset setup correctly.\n\nThis is why datasets are important:\n- It's an organized way to structure how the data and labels are loaded into the model.\n- We can then wrap the dataset in a dataloader and pytorch will handle batching the shuffling the data for us when training the model!","metadata":{"editable":false}},{"cell_type":"code","source":"class PlayingCardDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data = ImageFolder(data_dir, transform=transform)\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        return self.data[idx]\n    \n    @property\n    def classes(self):\n        return self.data.classes","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:27.155118Z","iopub.execute_input":"2025-06-28T14:49:27.155504Z","iopub.status.idle":"2025-06-28T14:49:27.159975Z","shell.execute_reply.started":"2025-06-28T14:49:27.155485Z","shell.execute_reply":"2025-06-28T14:49:27.159283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create Test Dataset","metadata":{"editable":false}},{"cell_type":"code","source":"dataset = PlayingCardDataset(\n    data_dir='/kaggle/input/cards-image-datasetclassification/train'\n)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:27.160778Z","iopub.execute_input":"2025-06-28T14:49:27.161041Z","iopub.status.idle":"2025-06-28T14:49:28.841989Z","shell.execute_reply.started":"2025-06-28T14:49:27.161016Z","shell.execute_reply":"2025-06-28T14:49:28.841156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(dataset)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:28.842856Z","iopub.execute_input":"2025-06-28T14:49:28.843401Z","iopub.status.idle":"2025-06-28T14:49:28.849121Z","shell.execute_reply.started":"2025-06-28T14:49:28.843377Z","shell.execute_reply":"2025-06-28T14:49:28.848525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image, label = dataset[0]\nimage\nprint(label)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:28.850892Z","iopub.execute_input":"2025-06-28T14:49:28.851085Z","iopub.status.idle":"2025-06-28T14:49:28.870144Z","shell.execute_reply.started":"2025-06-28T14:49:28.851070Z","shell.execute_reply":"2025-06-28T14:49:28.869498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Get a dictionnary associating target values with folder names\ndata_dir = '/kaggle/input/cards-image-datasetclassification/train'\ntarget_to_class = {v: k for k, v in ImageFolder(data_dir).class_to_idx.items()}\nprint(target_to_class)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:28.870864Z","iopub.execute_input":"2025-06-28T14:49:28.871039Z","iopub.status.idle":"2025-06-28T14:49:29.169988Z","shell.execute_reply.started":"2025-06-28T14:49:28.871025Z","shell.execute_reply":"2025-06-28T14:49:29.169183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((128,128)),\n    transforms.ToTensor(),\n])\n\ndata_dir = '/kaggle/input/cards-image-datasetclassification/train'\ndataset = PlayingCardDataset(data_dir, transform)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.170832Z","iopub.execute_input":"2025-06-28T14:49:29.171672Z","iopub.status.idle":"2025-06-28T14:49:29.287279Z","shell.execute_reply.started":"2025-06-28T14:49:29.171651Z","shell.execute_reply":"2025-06-28T14:49:29.286521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image, label = dataset[112]\nimage.shape","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.288320Z","iopub.execute_input":"2025-06-28T14:49:29.288989Z","iopub.status.idle":"2025-06-28T14:49:29.296251Z","shell.execute_reply.started":"2025-06-28T14:49:29.288965Z","shell.execute_reply":"2025-06-28T14:49:29.295653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# iterate over dataset\nfor image, label in dataset:\n    break","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.296980Z","iopub.execute_input":"2025-06-28T14:49:29.297172Z","iopub.status.idle":"2025-06-28T14:49:29.309581Z","shell.execute_reply.started":"2025-06-28T14:49:29.297156Z","shell.execute_reply":"2025-06-28T14:49:29.308960Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataloaders\n\n- Batching our dataset\n- It's faster to train the model in batches instead of one at a time.","metadata":{"editable":false}},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.310554Z","iopub.execute_input":"2025-06-28T14:49:29.310878Z","iopub.status.idle":"2025-06-28T14:49:29.323997Z","shell.execute_reply.started":"2025-06-28T14:49:29.310855Z","shell.execute_reply":"2025-06-28T14:49:29.323095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, labels in dataloader:\n    break","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.324812Z","iopub.execute_input":"2025-06-28T14:49:29.325066Z","iopub.status.idle":"2025-06-28T14:49:29.410373Z","shell.execute_reply.started":"2025-06-28T14:49:29.325038Z","shell.execute_reply":"2025-06-28T14:49:29.409581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images.shape, labels.shape","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.411199Z","iopub.execute_input":"2025-06-28T14:49:29.411494Z","iopub.status.idle":"2025-06-28T14:49:29.416745Z","shell.execute_reply.started":"2025-06-28T14:49:29.411469Z","shell.execute_reply":"2025-06-28T14:49:29.416142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.417347Z","iopub.execute_input":"2025-06-28T14:49:29.417536Z","iopub.status.idle":"2025-06-28T14:49:29.434109Z","shell.execute_reply.started":"2025-06-28T14:49:29.417521Z","shell.execute_reply":"2025-06-28T14:49:29.433506Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 2. Pytorch Model\n\nPytorch datasets have a structured way of organizing your data, pytorch models follow a similar paradigm.\n- We could create the model from scratch defining each layer.\n- However for tasks like image classification, many of the state of the art architectures are readily available and we can import them from packages like timm.\n- The main layer we need to modify is the final layer. Here we have 53 targets, so we will modify the last layer for this.","metadata":{"editable":false}},{"cell_type":"code","source":"class SimpleCardClassifer(nn.Module):\n    def __init__(self, num_classes=53):\n        super(SimpleCardClassifer, self).__init__()\n        # Where we define all the parts of the model\n        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n\n        enet_out_size = 1280\n        # Make a classifier\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(enet_out_size, num_classes)\n        )\n    \n    def forward(self, x):\n        # Connect these parts and return the output\n        x = self.features(x)\n        output = self.classifier(x)\n        return output","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.436732Z","iopub.execute_input":"2025-06-28T14:49:29.436959Z","iopub.status.idle":"2025-06-28T14:49:29.448710Z","shell.execute_reply.started":"2025-06-28T14:49:29.436942Z","shell.execute_reply":"2025-06-28T14:49:29.448063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = SimpleCardClassifer(num_classes=53)\nprint(str(model)[:500])","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.449424Z","iopub.execute_input":"2025-06-28T14:49:29.450218Z","iopub.status.idle":"2025-06-28T14:49:29.710217Z","shell.execute_reply.started":"2025-06-28T14:49:29.450176Z","shell.execute_reply":"2025-06-28T14:49:29.709521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"example_out = model(images)\nexample_out.shape    # [batch_size, num_classes]","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:29.710906Z","iopub.execute_input":"2025-06-28T14:49:29.711112Z","iopub.status.idle":"2025-06-28T14:49:30.453923Z","shell.execute_reply.started":"2025-06-28T14:49:29.711095Z","shell.execute_reply":"2025-06-28T14:49:30.453104Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3. The training loop\n\n- Now that we finished creating the general paradigm of pytorch datasets and models, we need to create the process of training this model.\n- Some things to consider: We want to validate our model on data it has not been trained on, so usually we split our data into training and validation datasets. This is easy because we can just create two datasets using our existing class.\n    - Terms:\n        - Epoch: One run through the entire training dataset.\n        - Step: One batch of data as defined in our dataloader\n- This loop works as follows: you load data into the model in batches, then calculate the loss and perform backpropagation.\n- Two things to select:\n    - optimizer, `adam` is the best place to start for most tasks.\n    - loss function: What the model will optimize for.","metadata":{"editable":false}},{"cell_type":"code","source":"# Loss function\ncriterion = nn.CrossEntropyLoss()\n# Optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:30.454784Z","iopub.execute_input":"2025-06-28T14:49:30.455339Z","iopub.status.idle":"2025-06-28T14:49:30.460762Z","shell.execute_reply.started":"2025-06-28T14:49:30.455316Z","shell.execute_reply":"2025-06-28T14:49:30.460068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion(example_out, labels)\nprint(example_out.shape, labels.shape)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:30.461400Z","iopub.execute_input":"2025-06-28T14:49:30.461642Z","iopub.status.idle":"2025-06-28T14:49:30.477916Z","shell.execute_reply.started":"2025-06-28T14:49:30.461625Z","shell.execute_reply":"2025-06-28T14:49:30.477294Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup Datasets","metadata":{"editable":false}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((128,128)),\n    transforms.ToTensor()\n])\n\ntrain_folder = '/kaggle/input/cards-image-datasetclassification/train'\nval_folder = '/kaggle/input/cards-image-datasetclassification/valid'\ntest_folder = '/kaggle/input/cards-image-datasetclassification/test'\n\ntrain_dataset = PlayingCardDataset(train_folder, transform=transform)\nval_dataset = PlayingCardDataset(val_folder, transform=transform)\ntest_dataset = PlayingCardDataset(test_folder, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False)\ntest_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:30.478698Z","iopub.execute_input":"2025-06-28T14:49:30.478984Z","iopub.status.idle":"2025-06-28T14:49:30.944200Z","shell.execute_reply.started":"2025-06-28T14:49:30.478958Z","shell.execute_reply":"2025-06-28T14:49:30.943649Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Simple Training Loop","metadata":{"editable":false}},{"cell_type":"code","source":"#To be able to train the model on gpu\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:30.944948Z","iopub.execute_input":"2025-06-28T14:49:30.945202Z","iopub.status.idle":"2025-06-28T14:49:30.982958Z","shell.execute_reply.started":"2025-06-28T14:49:30.945179Z","shell.execute_reply":"2025-06-28T14:49:30.982117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 5\ntrain_losses, val_losses = [], []\n\nmodel = SimpleCardClassifer(num_classes=53)\nmodel.to(device)\n\n#You have to set the loss function and the optimizer here too, in order for the model to train properly :\n# Loss function\ncriterion = nn.CrossEntropyLoss()\n# Optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()\n    running_loss = 0.0\n    for images, labels in tqdm(train_loader, desc='Training loop'):\n        # Move inputs and labels to the device\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * labels.size(0)\n    train_loss = running_loss / len(train_loader.dataset)\n    train_losses.append(train_loss)\n    \n    # Validation phase\n    model.eval()\n    running_loss = 0.0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc='Validation loop'):\n            # Move inputs and labels to the device\n            images, labels = images.to(device), labels.to(device)\n         \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * labels.size(0)\n    val_loss = running_loss / len(val_loader.dataset)\n    val_losses.append(val_loss)\n    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:49:30.983783Z","iopub.execute_input":"2025-06-28T14:49:30.984044Z","iopub.status.idle":"2025-06-28T14:51:52.863353Z","shell.execute_reply.started":"2025-06-28T14:49:30.984026Z","shell.execute_reply":"2025-06-28T14:51:52.862469Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize Losses\n\n- Now, we will plot the training and validation loss over each epoch to visualize how the model learned during training. This helps us assess performance and detect issues like overfitting or underfitting.","metadata":{"editable":false}},{"cell_type":"code","source":"plt.plot(train_losses, label='Training loss')\nplt.plot(val_losses, label='Validation loss')\nplt.legend()\nplt.title(\"Loss over epochs\")\nplt.show()","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:51:52.864277Z","iopub.execute_input":"2025-06-28T14:51:52.864574Z","iopub.status.idle":"2025-06-28T14:51:53.039411Z","shell.execute_reply.started":"2025-06-28T14:51:52.864547Z","shell.execute_reply":"2025-06-28T14:51:53.038634Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Bonus:** Evaluating the Results\n- Now, we will load and preprocess an image, make a prediction using the trained model, and visualize the predicted class probabilities alongside the original image. This helps us understand what the model sees and how confident it is in its predictions.","metadata":{"editable":false}},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load and preprocess the image\ndef preprocess_image(image_path, transform):\n    image = Image.open(image_path).convert(\"RGB\")\n    return image, transform(image).unsqueeze(0)\n\n# Predict using the model\ndef predict(model, image_tensor, device):\n    model.eval()\n    with torch.no_grad():\n        image_tensor = image_tensor.to(device)\n        outputs = model(image_tensor)\n        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n    return probabilities.cpu().numpy().flatten()\n\n# Visualization\ndef visualize_predictions(original_image, probabilities, class_names):\n    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n    \n    # Display image\n    axarr[0].imshow(original_image)\n    axarr[0].axis(\"off\")\n    \n    # Display predictions\n    axarr[1].barh(class_names, probabilities)\n    axarr[1].set_xlabel(\"Probability\")\n    axarr[1].set_title(\"Class Predictions\")\n    axarr[1].set_xlim(0, 1)\n\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\ntest_image = \"/kaggle/input/cards-image-datasetclassification/test/five of diamonds/2.jpg\"\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor()\n])\n\noriginal_image, image_tensor = preprocess_image(test_image, transform)\nprobabilities = predict(model, image_tensor, device)\n\n# Assuming dataset.classes gives the class names\nclass_names = dataset.classes \nvisualize_predictions(original_image, probabilities, class_names)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:51:53.040296Z","iopub.execute_input":"2025-06-28T14:51:53.040816Z","iopub.status.idle":"2025-06-28T14:51:53.680923Z","shell.execute_reply.started":"2025-06-28T14:51:53.040797Z","shell.execute_reply":"2025-06-28T14:51:53.679989Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Iterating over 10 samples\n- Now, we will randomly select 10 test images, predict their class probabilities using the model, and display each image with its predicted probabilities.","metadata":{"editable":false}},{"cell_type":"code","source":"#Iterating over 10 samples using numpy\nfrom glob import glob\ntest_images = glob('../input/cards-image-datasetclassification/test/*/*')\ntest_examples = np.random.choice(test_images, 10)\n\nfor example in test_examples:\n    original_image, image_tensor = preprocess_image(example, transform)\n    probabilities = predict(model, image_tensor, device)\n\n    # Assuming dataset.classes gives the class names\n    class_names = dataset.classes \n    visualize_predictions(original_image, probabilities, class_names)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:51:53.681889Z","iopub.execute_input":"2025-06-28T14:51:53.682119Z","iopub.status.idle":"2025-06-28T14:52:00.545114Z","shell.execute_reply.started":"2025-06-28T14:51:53.682100Z","shell.execute_reply":"2025-06-28T14:52:00.544264Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 📊 Evaluating Model Accuracy on Validation, Test, and Training Sets \n\n- Calculate the accuracy of our model on the validation set, the test set and the training set.","metadata":{"editable":false}},{"cell_type":"code","source":"# Compute accuracy for validation set, test set and training set :\n\n# Validation acuracy\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in tqdm(val_loader, desc='Validation loop'):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n# Get predicted class by selecting the class with highest score\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\nval_accuracy = correct / total\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")    \n\n# Test accuracy\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader, desc='Test loop'):\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\ntest_accuracy = correct / total\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n\n\n\n# Bonus ! Training accuracy :\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in tqdm(train_loader, desc='Training loop'):\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\ntrain_accuracy = correct / total\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-06-28T14:52:00.546218Z","iopub.execute_input":"2025-06-28T14:52:00.546520Z","iopub.status.idle":"2025-06-28T14:52:20.307486Z","shell.execute_reply.started":"2025-06-28T14:52:00.546497Z","shell.execute_reply":"2025-06-28T14:52:20.306679Z"}},"outputs":[],"execution_count":null}]}